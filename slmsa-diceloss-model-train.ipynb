{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906},{"sourceId":6836551,"sourceType":"datasetVersion","datasetId":3930592},{"sourceId":6940874,"sourceType":"datasetVersion","datasetId":3986015}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport sys\n\nmodule_path = '/kaggle/input/bratsslmsamodel'  # Update this with the correct path\nsys.path.append(module_path)\n\n#Import your module\nimport bratsslmsa\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-11T09:02:19.925267Z","iopub.execute_input":"2023-11-11T09:02:19.926281Z","iopub.status.idle":"2023-11-11T09:02:37.531252Z","shell.execute_reply.started":"2023-11-11T09:02:19.926240Z","shell.execute_reply":"2023-11-11T09:02:37.530235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nmodule_path = '/kaggle/input/diceioumetrics4ch'  # Update this with the correct path\nsys.path.append(module_path)\n\nimport diceioumetrics4ch\nfrom diceioumetrics4ch import dice_loss,dice_coefficient,IoUClassMetrics","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:02:37.533584Z","iopub.execute_input":"2023-11-11T09:02:37.534464Z","iopub.status.idle":"2023-11-11T09:02:37.550058Z","shell.execute_reply.started":"2023-11-11T09:02:37.534425Z","shell.execute_reply":"2023-11-11T09:02:37.549055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow_addons","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:02:37.551219Z","iopub.execute_input":"2023-11-11T09:02:37.551794Z","iopub.status.idle":"2023-11-11T09:02:49.441907Z","shell.execute_reply.started":"2023-11-11T09:02:37.551765Z","shell.execute_reply":"2023-11-11T09:02:49.439558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport nibabel as nib\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport glob\nimport tensorflow as tf\nfrom tensorflow_addons.optimizers import AdamW\nfrom tensorflow.keras.optimizers.schedules import CosineDecay\nimport keras.optimizers as optim\nfrom tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,ReduceLROnPlateau,EarlyStopping\nimport numpy as np\nimport nibabel as nib\nimport glob\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport random\nfrom tensorflow.keras.models import load_model\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:02:49.445743Z","iopub.execute_input":"2023-11-11T09:02:49.446404Z","iopub.status.idle":"2023-11-11T09:02:51.254705Z","shell.execute_reply.started":"2023-11-11T09:02:49.446343Z","shell.execute_reply":"2023-11-11T09:02:51.252984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Define a function to load and preprocess a single volume\ndef load_and_preprocess_volume(volume_path, mask_path):\n    \n    # Load the volume and mask for each channel\n    t2_volume = nib.load(volume_path[0]).get_fdata()\n    t2_volume_scaled = scaler.fit_transform(t2_volume.reshape(-1, t2_volume.shape[-1])).reshape(t2_volume.shape)\n    t1ce_volume = nib.load(volume_path[1]).get_fdata() \n    t1ce_volume_scaled = scaler.fit_transform(t1ce_volume.reshape(-1, t1ce_volume.shape[-1])).reshape(t1ce_volume.shape)\n    flair_volume = nib.load(volume_path[2]).get_fdata()\n    flair_volume_scaled = scaler.fit_transform(flair_volume.reshape(-1, flair_volume.shape[-1])).reshape(flair_volume.shape)\n    mask = nib.load(mask_path).get_fdata().astype(np.uint8)\n    mask[mask == 4] = 3  # Reassign mask values 4 to 3 or perform any other necessary preprocessing\n\n    # Combine the channels\n    combined_x = np.stack([t2_volume_scaled, t1ce_volume_scaled, flair_volume_scaled], axis=-1)\n    return combined_x, mask\n\n# Define a data generator\ndef custom_datagen(volume_path, mask_paths, batch_size):\n    \n    num_samples = len(volume_path)\n    print(\"volume_path len:\",len(volume_path))\n    while True:\n        for i in range(0, num_samples, batch_size):\n            batch_volume_paths = volume_path[i:i + batch_size]\n            batch_mask_paths = mask_paths[i:i + batch_size]\n            X = []\n            Y = []\n            for volume_path1, mask_path in zip(batch_volume_paths, batch_mask_paths):\n                             \n                image, mask = load_and_preprocess_volume(volume_path1, mask_path)\n\n                # Crop to a size divisible by the patch size\n                image = image[56:184, 56:184, 13:141]\n                mask = mask[56:184, 56:184, 13:141]\n                temp_mask= to_categorical(mask, num_classes=4)\n               \n                X.append(image)\n                Y.append(temp_mask)\n            \n            X = np.array(X)\n            Y = np.array(Y)\n            \n            yield X, Y\n\n# Define the data directory\ndata_directory = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n\n# Create lists of file paths\nt2_list = sorted(glob.glob(os.path.join(data_directory,'*/','*_t2.nii'), recursive=True))\nremove = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_t2.nii' \nt2_list = [item for item in t2_list if item != remove]\nt1ce_list = sorted(glob.glob(os.path.join(data_directory, '*/','*_t1ce.nii'), recursive=True))\nremove1 = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_t1ce.nii'\nt1ce_list = [item for item in t1ce_list if item != remove1]\nflair_list = sorted(glob.glob(os.path.join(data_directory,'*/','*_flair.nii'), recursive=True))\nremove2 = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_flair.nii'\nflair_list = [item for item in flair_list if item != remove2]\nmask_list = sorted(glob.glob(os.path.join(data_directory, '*/','*_seg.nii'), recursive=True))\n\n# Create data generators\nbatch_size = 4\ntrain_image_paths, val_image_paths, train_mask_paths, val_mask_paths = train_test_split( list(zip(t2_list, t1ce_list, flair_list)), mask_list, test_size=0.3, random_state=42)\ntrain_image_paths, test_image_paths, train_mask_paths, test_mask_paths = train_test_split( train_image_paths, train_mask_paths, test_size=0.4, random_state=42)\nprint(\"train_image_paths =\",len(train_image_paths))\nprint(\"test_image_paths =\",len(test_image_paths))\nprint(\"val_image_paths =\",len(val_image_paths))\n\ntrain_dataset = custom_datagen(train_image_paths, train_mask_paths, batch_size)\nval_dataset = custom_datagen(val_image_paths, val_mask_paths, batch_size)\ntest_dataset = custom_datagen(test_image_paths, test_mask_paths, batch_size)\nprint(train_dataset, val_dataset, test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:02:51.280511Z","iopub.execute_input":"2023-11-11T09:02:51.280895Z","iopub.status.idle":"2023-11-11T09:02:52.366891Z","shell.execute_reply.started":"2023-11-11T09:02:51.280835Z","shell.execute_reply":"2023-11-11T09:02:52.365685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load and preprocess a single volume from the test dataset\n# for data in test_dataset:\n#     test_img_input, test_mask = data\n#     print(\"test_img_input.shape\",test_img_input.shape)\n#     print(\"test_mask.shape\",test_mask.shape)\n    \n#     #Here, test_img_input is the input image, and test_mask is the corresponding mask\n#     test_mask_argmax=np.argmax(test_mask, axis=4)\n#     print(\"test_mask_argmax.shape\",test_mask_argmax.shape)\n    \n# #     test_img = np.expand_dims(test_img_input, axis=4)\n# #     print(\"test_img.shape\",test_img.shape)\n    \n#     # Predict the mask for the input image\n#     test_prediction = model.predict(test_img_input)\n#     print(\"test_prediction.shape\",test_prediction.shape)\n#     # Assuming your model's output has multiple channels, get the argmax of the last dimension\n#     test_prediction_argmax = np.argmax(test_prediction, axis=4)\n    \n#     print(\"test_prediction=\",test_prediction.shape)\n#     print(\"test_prediction_argmax=\",np.unique(test_prediction_argmax)) \n#     print(\"test_mask_argmax=\",np.unique(test_mask_argmax))\n#     print(\"test_mask=\",np.unique(test_mask))\n#     print(\"test_prediction=\",np.unique(test_prediction))\n#     n_slice = 85\n#     plt.figure(figsize=(12, 8))\n#     plt.subplot(231)\n#     plt.title('Testing Image')\n#     plt.imshow(test_img_input[0,:,:,n_slice,2], cmap='gray')\n#     plt.subplot(232)\n#     plt.title('Testing Label')\n#     plt.imshow(test_mask_argmax[0,:,:,n_slice])\n#     plt.subplot(233)\n#     plt.title('Prediction on test image')\n#     plt.imshow(test_prediction_argmax[0,:,:, n_slice])\n#     plt.show()\n#     break  # Stop after predicting one set\n\n# # test_prediction_argmax will contain the predicted mask for the input image\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:02:52.368323Z","iopub.execute_input":"2023-11-11T09:02:52.369149Z","iopub.status.idle":"2023-11-11T09:02:52.375008Z","shell.execute_reply.started":"2023-11-11T09:02:52.369114Z","shell.execute_reply":"2023-11-11T09:02:52.373469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = 1e-4\nepoch=20\nimport keras.optimizers as optim\nfrom tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,ReduceLROnPlateau,EarlyStopping\nfrom tensorflow_addons.optimizers import AdamW\n\n\nmodel_path = '/kaggle/working/brats_slmsa_diceloss.hdf5'\ncsv_path = '/kaggle/working/brats_slmsa_diceloss.csv'\n\nsteps_per_epoch = len(train_image_paths)//batch_size\nval_steps_per_epoch = len(val_image_paths)//batch_size\n\n\nfrom  bratsslmsa import slm_sa\nnum_classes = 4\niou_metrics = IoUClassMetrics() \n#total_steps = steps_per_epoch * epoch\n#total_loss = TotalLoss3D()\nweight_decay = 1e-5  # desired weight decay\nmetrics =[dice_coefficient,iou_metrics]\n# Compile your model with the AdamW optimizer\noptimizer = AdamW(learning_rate=LR, weight_decay=weight_decay)\nmodel = slm_sa((128,128,128,3),4)\nmodel.compile(optimizer=optimizer,\n              loss=dice_loss,\n              metrics=metrics)\ncallbacks = [\n    ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-9, verbose=1),\n    CSVLogger(csv_path),\n    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=False)\n]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:02:52.376666Z","iopub.execute_input":"2023-11-11T09:02:52.377622Z","iopub.status.idle":"2023-11-11T09:02:54.315516Z","shell.execute_reply.started":"2023-11-11T09:02:52.377577Z","shell.execute_reply":"2023-11-11T09:02:54.313900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train_dataset,\n          steps_per_epoch=steps_per_epoch,\n          epochs=20,\n          verbose=1,\n          validation_data= val_dataset,\n          validation_steps=val_steps_per_epoch,\n          callbacks=callbacks)\n\nmodel.save(model_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-11T09:02:54.320140Z","iopub.execute_input":"2023-11-11T09:02:54.320511Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
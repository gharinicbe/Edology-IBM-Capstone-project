{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906},{"sourceId":6836551,"sourceType":"datasetVersion","datasetId":3930592},{"sourceId":6940874,"sourceType":"datasetVersion","datasetId":3986015},{"sourceId":6978666,"sourceType":"datasetVersion","datasetId":4010196}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport sys\n\nmodule_path = '/kaggle/input/bratsslmsamodel'  # Update this with the correct path\nsys.path.append(module_path)\n\n#Import your module\nimport bratsslmsa\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-19T07:02:08.007962Z","iopub.execute_input":"2023-11-19T07:02:08.008368Z","iopub.status.idle":"2023-11-19T07:02:22.002903Z","shell.execute_reply.started":"2023-11-19T07:02:08.008333Z","shell.execute_reply":"2023-11-19T07:02:22.000963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n\nmodule_path = '/kaggle/input/diceioumetrics4ch'  # Update this with the correct path\nsys.path.append(module_path)\n\nimport diceioumetrics4ch\nfrom diceioumetrics4ch import dice_loss,dice_coefficient,IoUClassMetrics","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:02:22.005098Z","iopub.execute_input":"2023-11-19T07:02:22.006599Z","iopub.status.idle":"2023-11-19T07:02:22.020130Z","shell.execute_reply.started":"2023-11-19T07:02:22.006526Z","shell.execute_reply":"2023-11-19T07:02:22.019102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow_addons","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:02:22.021282Z","iopub.execute_input":"2023-11-19T07:02:22.021528Z","iopub.status.idle":"2023-11-19T07:02:33.106038Z","shell.execute_reply.started":"2023-11-19T07:02:22.021505Z","shell.execute_reply":"2023-11-19T07:02:33.104761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport nibabel as nib\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport glob\nimport tensorflow as tf\nfrom tensorflow_addons.optimizers import AdamW\nimport keras.optimizers as optim\nfrom tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,ReduceLROnPlateau,EarlyStopping\nimport matplotlib.pyplot as plt\nimport random\nfrom tensorflow.keras.models import load_model\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:02:33.109605Z","iopub.execute_input":"2023-11-19T07:02:33.110082Z","iopub.status.idle":"2023-11-19T07:02:34.165800Z","shell.execute_reply.started":"2023-11-19T07:02:33.110047Z","shell.execute_reply":"2023-11-19T07:02:34.164874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Define a function to load and preprocess a single volume\ndef load_and_preprocess_volume(volume_path, mask_path):\n    \n    # Load the volume and mask for each channel\n    t2_volume = nib.load(volume_path[0]).get_fdata()\n    t2_volume_scaled = scaler.fit_transform(t2_volume.reshape(-1, t2_volume.shape[-1])).reshape(t2_volume.shape)\n    t1ce_volume = nib.load(volume_path[1]).get_fdata() \n    t1ce_volume_scaled = scaler.fit_transform(t1ce_volume.reshape(-1, t1ce_volume.shape[-1])).reshape(t1ce_volume.shape)\n    flair_volume = nib.load(volume_path[2]).get_fdata()\n    flair_volume_scaled = scaler.fit_transform(flair_volume.reshape(-1, flair_volume.shape[-1])).reshape(flair_volume.shape)\n    mask = nib.load(mask_path).get_fdata().astype(np.uint8)\n    mask[mask == 4] = 3  # Reassign mask values 4 to 3 or perform any other necessary preprocessing\n\n    # Combine the channels\n    combined_x = np.stack([t2_volume_scaled, t1ce_volume_scaled, flair_volume_scaled], axis=-1)\n    return combined_x, mask\n\n# Define a data generator\ndef custom_datagen(volume_path, mask_paths, batch_size):\n    \n    num_samples = len(volume_path)\n    print(\"volume_path len:\",len(volume_path))\n    while True:\n        for i in range(0, num_samples, batch_size):\n            batch_volume_paths = volume_path[i:i + batch_size]\n            batch_mask_paths = mask_paths[i:i + batch_size]\n            X = []\n            Y = []\n            for volume_path1, mask_path in zip(batch_volume_paths, batch_mask_paths):\n                             \n                image, mask = load_and_preprocess_volume(volume_path1, mask_path)\n\n                # Crop to a size divisible by the patch size\n                image = image[56:184, 56:184, 13:141]\n                mask = mask[56:184, 56:184, 13:141]\n                temp_mask= to_categorical(mask, num_classes=4)\n               \n                X.append(image)\n                Y.append(temp_mask)\n            \n            X = np.array(X)\n            Y = np.array(Y)\n            \n            yield X, Y\n\n# Define the data directory\ndata_directory = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n\n# Create lists of file paths\nt2_list = sorted(glob.glob(os.path.join(data_directory,'*/','*_t2.nii'), recursive=True))\nremove = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_t2.nii' \nt2_list = [item for item in t2_list if item != remove]\nt1ce_list = sorted(glob.glob(os.path.join(data_directory, '*/','*_t1ce.nii'), recursive=True))\nremove1 = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_t1ce.nii'\nt1ce_list = [item for item in t1ce_list if item != remove1]\nflair_list = sorted(glob.glob(os.path.join(data_directory,'*/','*_flair.nii'), recursive=True))\nremove2 = '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_flair.nii'\nflair_list = [item for item in flair_list if item != remove2]\nmask_list = sorted(glob.glob(os.path.join(data_directory, '*/','*_seg.nii'), recursive=True))\n\n# Create data generators\nbatch_size = 2\ntrain_image_paths, val_image_paths, train_mask_paths, val_mask_paths = train_test_split( list(zip(t2_list, t1ce_list, flair_list)), mask_list, test_size=0.4, random_state=42)\ntrain_image_paths, test_image_paths, train_mask_paths, test_mask_paths = train_test_split( train_image_paths, train_mask_paths, test_size=0.2, random_state=42)\nprint(\"train_image_paths =\",len(train_image_paths))\nprint(\"test_image_paths =\",len(test_image_paths))\nprint(\"val_image_paths =\",len(val_image_paths))\n\ntrain_dataset = custom_datagen(train_image_paths, train_mask_paths, batch_size)\nval_dataset = custom_datagen(val_image_paths, val_mask_paths, batch_size)\ntest_dataset = custom_datagen(test_image_paths, test_mask_paths, batch_size)\nprint(train_dataset, val_dataset, test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:02:34.167090Z","iopub.execute_input":"2023-11-19T07:02:34.167374Z","iopub.status.idle":"2023-11-19T07:02:35.135329Z","shell.execute_reply.started":"2023-11-19T07:02:34.167350Z","shell.execute_reply":"2023-11-19T07:02:35.134437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load and preprocess a single volume from the test dataset\n# for data in test_dataset:\n#     test_img_input, test_mask = data\n#     print(\"test_img_input.shape\",test_img_input.shape)\n#     print(\"test_mask.shape\",test_mask.shape)\n    \n#     #Here, test_img_input is the input image, and test_mask is the corresponding mask\n#     test_mask_argmax=np.argmax(test_mask, axis=4)\n#     print(\"test_mask_argmax.shape\",test_mask_argmax.shape)\n    \n# #     test_img = np.expand_dims(test_img_input, axis=4)\n# #     print(\"test_img.shape\",test_img.shape)\n    \n#     # Predict the mask for the input image\n#     test_prediction = model.predict(test_img_input)\n#     print(\"test_prediction.shape\",test_prediction.shape)\n#     # Assuming your model's output has multiple channels, get the argmax of the last dimension\n#     test_prediction_argmax = np.argmax(test_prediction, axis=4)\n    \n#     print(\"test_prediction=\",test_prediction.shape)\n#     print(\"test_prediction_argmax=\",np.unique(test_prediction_argmax)) \n#     print(\"test_mask_argmax=\",np.unique(test_mask_argmax))\n#     print(\"test_mask=\",np.unique(test_mask))\n#     print(\"test_prediction=\",np.unique(test_prediction))\n#     n_slice = 85\n#     plt.figure(figsize=(12, 8))\n#     plt.subplot(231)\n#     plt.title('Testing Image')\n#     plt.imshow(test_img_input[0,:,:,n_slice,2], cmap='gray')\n#     plt.subplot(232)\n#     plt.title('Testing Label')\n#     plt.imshow(test_mask_argmax[0,:,:,n_slice])\n#     plt.subplot(233)\n#     plt.title('Prediction on test image')\n#     plt.imshow(test_prediction_argmax[0,:,:, n_slice])\n#     plt.show()\n#     break  # Stop after predicting one set\n\n# # test_prediction_argmax will contain the predicted mask for the input image\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:02:35.136425Z","iopub.execute_input":"2023-11-19T07:02:35.136940Z","iopub.status.idle":"2023-11-19T07:02:35.143617Z","shell.execute_reply.started":"2023-11-19T07:02:35.136910Z","shell.execute_reply":"2023-11-19T07:02:35.142036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow_addons.optimizers import AdamW\nfrom keras.utils import custom_object_scope\nfrom bratsslmsa import ShortTermMemoryAttentionBlock, LongTermMemoryAttentionBlock  # Import your custom layers\n\nmodelpath = '/kaggle/input/brats-slmsa-7diceloss/brats_slmsa_7diceloss.hdf5'\n\nif os.path.exists(modelpath):\n    # Load the model with custom layer registration\n    with custom_object_scope({\n        'ShortTermMemoryAttentionBlock': ShortTermMemoryAttentionBlock,\n        'LongTermMemoryAttentionBlock': LongTermMemoryAttentionBlock, \n        'dice_loss':dice_loss,\n        'dice_coefficient': dice_coefficient,\n        'IoUClassMetrics' : IoUClassMetrics\n            }):\n        model = load_model(modelpath)\nelse:\n    print(f\"The model file '{modelpath}' does not exist.\")\n\n ","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:02:35.144981Z","iopub.execute_input":"2023-11-19T07:02:35.145245Z","iopub.status.idle":"2023-11-19T07:02:39.326437Z","shell.execute_reply.started":"2023-11-19T07:02:35.145223Z","shell.execute_reply":"2023-11-19T07:02:39.324900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = 1e-4\nepoch=20\nimport keras.optimizers as optim\nfrom tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger,ReduceLROnPlateau,EarlyStopping\nfrom tensorflow_addons.optimizers import AdamW\n\n\nmodel_hdf5_path = \"/kaggle/working/brats_slmsa_mordat_diceloss.hdf5\"\ncsv_path = '/kaggle/working/brats_slmsa_mordat_diceloss.csv'\n\nsteps_per_epoch = len(train_image_paths)//batch_size\nval_steps_per_epoch = len(val_image_paths)//batch_size\n\n\nfrom  bratsslmsa import slm_sa\nnum_classes = 4\niou_metrics = IoUClassMetrics() \n#total_steps = steps_per_epoch * epoch\n#total_loss = TotalLoss3D()\nweight_decay = 1e-5  # desired weight decay\nmetrics =[dice_coefficient,iou_metrics]\n# Compile your model with the AdamW optimizer\noptimizer = AdamW(learning_rate=LR, weight_decay=weight_decay)\n\nmodel.compile(optimizer=optimizer,\n              loss=dice_loss,\n              metrics=metrics)\ncallbacks = [\n    ModelCheckpoint(model_hdf5_path, verbose=1, save_best_only=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-9, verbose=1),\n    CSVLogger(csv_path),\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:02:39.328371Z","iopub.execute_input":"2023-11-19T07:02:39.328705Z","iopub.status.idle":"2023-11-19T07:02:39.363440Z","shell.execute_reply.started":"2023-11-19T07:02:39.328681Z","shell.execute_reply":"2023-11-19T07:02:39.362256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train_dataset,\n          steps_per_epoch=steps_per_epoch,\n          epochs=20,\n          verbose=1,\n          validation_data= val_dataset,\n          validation_steps=val_steps_per_epoch,\n          callbacks=callbacks)\n\nmodel.save(model_hdf5_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-19T07:02:39.365188Z","iopub.execute_input":"2023-11-19T07:02:39.365649Z"},"trusted":true},"execution_count":null,"outputs":[]}]}